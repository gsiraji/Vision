{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision.utils import make_grid as makeGrid\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from torchvision import transforms\n",
    "import copy\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, predictions = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(predictions == labels).item() / len(predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showBatch(data_loader):\n",
    "    for images, labels in data_loader:\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        ax.imshow(makeGrid(images, nrow = 16).permute(1, 2, 0))\n",
    "        ax.axis('off')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showSample(img, label):\n",
    "    print(\"Label:\", dataset.classes[label], \"(Class No: \"+ str(label) + \")\")\n",
    "    plt.imshow(img.permute(1, 2, 0))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotAccuracies(history):\n",
    "    accuracies = [x['val_acc'] for x in history]\n",
    "    plt.plot(accuracies, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy vs. No. of epochs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotLosses(history):\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictImage(img, model):\n",
    "    # Convert to a batch of 1\n",
    "    xb = to_device(img.unsqueeze(0), device)\n",
    "    # Get predictions from model\n",
    "    yb = model(xb)\n",
    "    # Pick index with highest probability\n",
    "    prob, preds  = torch.max(yb, dim=1)\n",
    "    # Retrieve the class label\n",
    "    return dataset.classes[preds[0].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path  = path+'/input/cat-or-dog'\n",
    "\n",
    "sorting_classes = os.listdir(data_path+'/train/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorting_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = path+'/train/train'\n",
    "test_path = path+'/test1/test1'\n",
    "train_files = os.listdir(train_path)\n",
    "test_files = os.listdir(test_path)\n",
    "\n",
    "class CatDogDataset(Dataset):\n",
    "    def __init__(self, file_list, dir, mode='train', transform = None):\n",
    "        self.file_list = file_list\n",
    "        self.dir = dir\n",
    "        self.mode= mode\n",
    "        self.transform = transform\n",
    "        if self.mode == 'train':\n",
    "            if 'dog' in self.file_list[0]:\n",
    "                self.label = 1\n",
    "            else:\n",
    "                self.label = 0\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(os.path.join(self.dir, self.file_list[idx]))\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.mode == 'train':\n",
    "            img = img.numpy()\n",
    "            return img.astype('float32'), self.label\n",
    "        else:\n",
    "            img = img.numpy()\n",
    "            return img.astype('float32'), self.file_list[idx]\n",
    "        \n",
    "\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.ColorJitter(),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "cat_files = [tf for tf in train_files if 'cat' in tf]\n",
    "dog_files = [tf for tf in train_files if 'dog' in tf]\n",
    "\n",
    "cats = CatDogDataset(cat_files, train_path, transform = data_transform)\n",
    "dogs = CatDogDataset(dog_files, train_path, transform = data_transform)\n",
    "\n",
    "catdogs = ConcatDataset([cats, dogs])\n",
    "\n",
    "\n",
    "dataloader = DataLoader(catdogs, batch_size = 32, shuffle=True, num_workers=4)\n",
    "\n",
    "samples, labels = iter(dataloader).next()\n",
    "plt.figure(figsize=(16,24))\n",
    "grid_imgs = torchvision.utils.make_grid(samples[:24])\n",
    "np_grid_imgs = grid_imgs.numpy()\n",
    "# in tensor, image is (batch, width, height), so you have to transpose it to (width, height, batch) in numpy to show it.\n",
    "plt.imshow(np.transpose(np_grid_imgs, (1,2,0)))\n",
    "\n",
    "\n",
    "\n",
    "model = torchvision.models.densenet121(pretrained=True)\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "\n",
    "num_ftrs = model.classifier.in_features\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 500),\n",
    "    nn.Linear(500, 2)\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002, amsgrad=True)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[500,1000,1500], gamma=0.5)\n",
    "\n",
    "\n",
    "\n",
    "epochs = 3\n",
    "itr = 1\n",
    "p_itr = 200\n",
    "model.train()\n",
    "total_loss = 0\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "for epoch in range(epochs):\n",
    "    for samples, labels in dataloader:\n",
    "        samples, labels = samples.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(samples)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        scheduler.step()\n",
    "        \n",
    "        if itr%p_itr == 0:\n",
    "            pred = torch.argmax(output, dim=1)\n",
    "            correct = pred.eq(labels)\n",
    "            acc = torch.mean(correct.float())\n",
    "            print('[Epoch {}/{}] Iteration {} -> Train Loss: {:.4f}, Accuracy: {:.3f}'.format(epoch+1, epochs, itr, total_loss/p_itr, acc))\n",
    "            loss_list.append(total_loss/p_itr)\n",
    "            acc_list.append(acc)\n",
    "            total_loss = 0\n",
    "            \n",
    "        itr += 1\n",
    "\n",
    "plt.plot(loss_list, label='loss')\n",
    "\n",
    "plt.plot(acc_list, label='accuracy')\n",
    "plt.legend()\n",
    "plt.title('training loss and accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
